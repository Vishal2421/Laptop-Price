{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Laptop Prices Prediction\nThis analysis and model will be used to find correlation between specs and laptop price aswell as being used to predict laptop prices in the future."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Variable Identification\nFirst I will explore each variable first, I want to find out the data type of each and how many null entries I have in the dataset."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"laptops = pd.read_csv('/kaggle/input/laptop-price/laptop_price.csv',encoding='latin-1')\nlaptops = laptops.set_index('laptop_ID')\nlaptops.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow! Not one missing entry! Don't you love it when this happens."},{"metadata":{"trusted":true},"cell_type":"code","source":"laptops.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"laptops.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Univariate Analysis\nNow I will visualize some features to try and find some outliers and see if we can find some interesting stats."},{"metadata":{"trusted":true},"cell_type":"code","source":"laptops['Company'].value_counts()\nfig_dims = (20, 6)\nfig, ax = plt.subplots(figsize=fig_dims)\nsb.countplot(x=\"Company\", data=laptops, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning & Prep\nNext, I will clean up all of the confusing categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"laptops[\"Ram\"] = laptops[\"Ram\"].str.replace('GB', '')\nlaptops[\"Weight\"] = laptops[\"Weight\"].str.replace('kg', '')\nlaptops['Memory'] = laptops['Memory'].astype(str).replace('\\.0', '', regex=True)\nlaptops[\"Memory\"] = laptops[\"Memory\"].str.replace('GB', '')\nlaptops[\"Memory\"] = laptops[\"Memory\"].str.replace('TB', '000')\nnew2 = laptops[\"Memory\"].str.split(\"+\", n = 1, expand = True)\nlaptops[\"first\"]= new2[0]\nlaptops[\"first\"]=laptops[\"first\"].str.strip()\nlaptops[\"second\"]= new2[1]\nlaptops[\"Layer1HDD\"] = laptops[\"first\"].apply(lambda x: 1 if \"HDD\" in x else 0)\nlaptops[\"Layer1SSD\"] = laptops[\"first\"].apply(lambda x: 1 if \"SSD\" in x else 0)\nlaptops[\"Layer1Hybrid\"] = laptops[\"first\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\nlaptops[\"Layer1Flash_Storage\"] = laptops[\"first\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)\nlaptops['first'] = laptops['first'].str.replace(r'\\D', '')\nlaptops[\"second\"].fillna(\"0\", inplace = True)\nlaptops[\"Layer2HDD\"] = laptops[\"second\"].apply(lambda x: 1 if \"HDD\" in x else 0)\nlaptops[\"Layer2SSD\"] = laptops[\"second\"].apply(lambda x: 1 if \"SSD\" in x else 0)\nlaptops[\"Layer2Hybrid\"] = laptops[\"second\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\nlaptops[\"Layer2Flash_Storage\"] = laptops[\"second\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)\nlaptops['second'] = laptops['second'].str.replace(r'\\D', '')\nlaptops[\"first\"] = laptops[\"first\"].astype(int)\nlaptops[\"second\"] = laptops[\"second\"].astype(int)\nlaptops[\"Total_Memory\"]=(laptops[\"first\"]*(laptops[\"Layer1HDD\"]+laptops[\"Layer1SSD\"]+laptops[\"Layer1Hybrid\"]+laptops[\"Layer1Flash_Storage\"])+laptops[\"second\"]*(laptops[\"Layer2HDD\"]+laptops[\"Layer2SSD\"]+laptops[\"Layer2Hybrid\"]+laptops[\"Layer2Flash_Storage\"]))\nlaptops[\"Memory\"]=laptops[\"Total_Memory\"]\nlaptops[\"HDD\"]=(laptops[\"first\"]*laptops[\"Layer1HDD\"]+laptops[\"second\"]*laptops[\"Layer2HDD\"])\nlaptops[\"SSD\"]=(laptops[\"first\"]*laptops[\"Layer1SSD\"]+laptops[\"second\"]*laptops[\"Layer2SSD\"])\nlaptops[\"Hybrid\"]=(laptops[\"first\"]*laptops[\"Layer1Hybrid\"]+laptops[\"second\"]*laptops[\"Layer2Hybrid\"])\nlaptops[\"Flash_Storage\"]=(laptops[\"first\"]*laptops[\"Layer1Flash_Storage\"]+laptops[\"second\"]*laptops[\"Layer2Flash_Storage\"])\nnew = laptops[\"ScreenResolution\"].str.split(\"x\", n = 1, expand = True) \nlaptops[\"X_res\"]= new[0]\nlaptops[\"Y_res\"]= new[1]\nlaptops[\"Y_res\"]= pd.to_numeric(laptops[\"Y_res\"])\nlaptops[\"Y_res\"]= laptops[\"Y_res\"].astype(float)\nlaptops[\"X_res\"]=(laptops['X_res'].str.replace(',','').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: pd.Series(x).astype(int)).mean(1))\nlaptops[\"X_res\"]=pd.to_numeric(laptops[\"X_res\"])\nlaptops[\"PPI\"]=(((laptops[\"X_res\"]**2+laptops[\"Y_res\"]**2)**(1/2))/laptops[\"Inches\"]).astype(float)\nlaptops[\"ScreenResolution\"]=(laptops[\"X_res\"]*laptops[\"Y_res\"]).astype(float)\nlaptops[\"Ram\"] = laptops[\"Ram\"].astype(int)\nlaptops[\"Weight\"] = laptops[\"Weight\"].astype(float)\nlaptops=laptops.drop(['first','second','Layer1HDD','Layer1SSD','Layer1Hybrid','Layer1Flash_Storage','Layer2HDD','Layer2SSD','Layer2Hybrid','Layer2Flash_Storage','Total_Memory'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"laptops.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bi-variate Analysis\nNow I will compare features against each other to try and find some correlation between them."},{"metadata":{"trusted":true},"cell_type":"code","source":"def correlation_heatmap(train):\n    correlations = train.corr()\n    \n    fig, ax = plt.subplots(figsize=(16,16))\n    sb.heatmap(correlations, vmax=1.0, center=0, fmt='.2f', square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\":.70})\n    plt.show()\ncorrelation_heatmap(laptops)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_dims = (20, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsb.scatterplot(data=laptops, x=\"Price_euros\", y=\"Ram\", ax=ax, s=75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_dims = (20, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nsb.scatterplot(data=laptops, x=\"Price_euros\", y=\"SSD\", ax=ax, s=75)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split Current Data\nNow I will split the target feature and from the dataset and sort out the current object features."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = laptops.drop(['Price_euros'],axis=1)\nY = laptops['Price_euros'].values\nX = X.select_dtypes(exclude=['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Models\nNow I will train a few models and compare them"},{"metadata":{"trusted":true},"cell_type":"code","source":"SGDreg = SGDRegressor()\nSGDreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = SGDreg.predict(X_train)\nsgd_mse = mean_squared_error(y_train, pred)\nsgd_rmse = np.sqrt(sgd_mse)\nsgd_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'alpha': 10.0 ** -np.arange(1, 7),\n    'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n    'penalty': ['l2', 'l1', 'elasticnet'],\n    'learning_rate': ['constant', 'optimal', 'invscaling'],\n    'max_iter': [1000, 5000, 10000]\n}\n\ngrid_search = GridSearchCV(SGDreg, param_grid)\ngrid_search.fit(X_train, y_train)\nprint(\"Best score: \" + str(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Kreg = KNeighborsRegressor()\nKreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = Kreg.predict(X_train)\nk_mse = mean_squared_error(y_train, pred)\nk_rmse = np.sqrt(k_mse)\nk_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'n_neighbors': np.arange(1, 12, 2),\n              'weights': ['uniform', 'distance']}\ngrid_search = GridSearchCV(Kreg, param_grid)\ngrid_search.fit(X_train, y_train)\nprint(\"Best score: \" + str(grid_search.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = grid_search.best_estimator_\nfinal_pred = final_model.predict(X_test)\nfinal_pred = final_pred.tolist()\nfor pred in range(0, len(final_pred)):\n    print(\"Predicition: \" + str(round(final_pred[pred], 2)) + \" Actual: \" + str(y_test[pred]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's plot our predicted prices compared to the actual prices."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_dims = (20, 10)\nfig, ax = plt.subplots(figsize=fig_dims)\nax.scatter(y_test, final_pred)\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}